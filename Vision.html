<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prompt engineering</title>
</head>

<body>



    <!doctype html>
    <html>

    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script src="https://cdn.tailwindcss.com"></script>
    </head>

    <body>
        <header class="text-gray-400 bg-gray-900 body-font">
            <div class="container mx-auto flex flex-wrap p-5 flex-col md:flex-row items-center">
                <a class="flex title-font font-medium items-center text-white mb-4 md:mb-0">
                    <img src="images/logo_2-removebg-preview.png" alt="" width="50px">
                    <span class="ml-3 text-xl">Vision</span>
                </a>
                <nav class="md:ml-auto flex flex-wrap items-center text-base justify-center">
                    <a class="mr-5 hover:text-white" href="index.html">Home</a>

                </nav>

            </div>
        </header>

        <section class="text-gray-400 bg-gray-900 body-font">
            <div class="container mx-auto flex px-5 py-24 items-center justify-center flex-col">
                <img class="lg:w-2/6 md:w-3/6 w-5/6 mb-10 object-cover object-center rounded" alt="hero"
                    src="images/vision.jpg">
                <div class="text-center lg:w-2/3 w-full">
                    <h1 class="title-font sm:text-4xl text-3xl mb-4 font-medium text-white">Vision</h1>
                    <p class="leading-relaxed mb-8">GPT-4 with Vision, sometimes referred to as GPT-4V or
                        gpt-4-vision-preview in the API, allows the model to take in images and answer questions about
                        them. Historically, language model systems have been limited by taking in a single input
                        modality, text. For many use cases, this constrained the areas where models like GPT-4 could be
                        used. <br>
                        GPT-4 with vision is currently available to all developers who have access to GPT-4 via the
                        gpt-4-vision-preview model and the Chat Completions API which has been updated to support image
                        inputs. Note that the Assistants API does not currently support image inputs


                    </p>
                </div>
            </div>

            <h1 style="font-size: 22px; padding-left: 25px; color: white;">Image Processing:</h1>
            <p style="padding-left: 25px; ">Image processing techniques involve manipulating and enhancing digital
                images to improve their quality or extract useful information. This includes operations such as
                filtering, edge detection, image segmentation, and feature extraction..

            </p>
            <h1 style="font-size: 22px; padding-left: 25px; color: white; padding-top: 15px;">Feature Extraction: </h1>
            <p style="padding-left: 25px;">Feature extraction involves identifying and extracting relevant information
                or patterns from images. This can include detecting edges, corners, textures, shapes, or other visual
                attributes that are important for a particular task.</p>
            <h1 style="font-size: 22px; padding-left: 25px; color: white; padding-top: 15px;">Object Detection and
                Recognition:
            </h1>
            <p style="padding-left: 25px;">Object detection algorithms identify and localize objects within an image or
                video, often by predicting bounding boxes around objects and assigning class labels to them. Object
                recognition goes a step further by identifying specific objects within an image and assigning them
                semantic labels.

            </p>
            <h1 style="font-size: 22px; padding-left: 25px; color: white; padding-top: 15px;">Semantic Segmentation:
            </h1>
            <p style="padding-left: 25px;"> Semantic segmentation involves partitioning an image into meaningful
                segments or regions and assigning each pixel a class label. This enables fine-grained understanding of
                the contents of an image, allowing algorithms to differentiate between different object categories and
                background regions.
            </p>

            <h1 style="font-size: 22px; padding-left: 25px; color: white; padding-top: 15px;">Deep Learning:
            </h1>
            <p style="padding-left: 25px;"> Deep learning, particularly convolutional neural networks (CNNs), has
                revolutionized computer vision by enabling end-to-end learning from raw pixel data. CNNs learn
                hierarchical representations of visual features directly from images, enabling them to achieve
                state-of-the-art performance on tasks such as image classification, object detection, and image
                segmentation.
            </p>

            <h1 style="font-size: 22px; padding-left: 25px; color: white; padding-top: 15px;">3D Vision:
            </h1>
            <p style="padding-left: 25px;"> 3D vision involves understanding and reconstructing the three-dimensional
                structure of objects and scenes from multiple 2D images or depth data. Techniques such as stereo vision,
                structure-from-motion, and depth estimation are used to infer depth and spatial relationships from
                visual data.

            </p>

            <h1 style="font-size: 22px; padding-left: 25px; color: white; padding-top: 15px;">Applications:
            </h1>
            <p style="padding-left: 25px; padding-bottom: 30px;" > Computer vision has a wide range of applications across various industries,
                including autonomous vehicles, surveillance, medical imaging, robotics, augmented reality, and
                image-based search and recommendation systems.

            </p>

        </section>


        <footer class="text-gray-400 bg-gray-900 body-font">
            <div class="container px-5 py-8 mx-auto flex items-center sm:flex-row flex-col">
                <a class="flex title-font font-medium items-center md:justify-start justify-center text-white">
                    <img src="images/logo_2-removebg-preview.png" alt="" width="18%">
                    <span class="ml-3 text-xl">OPEN AI</span>
                </a>
                <p class="text-sm text-gray-400 sm:ml-4 sm:pl-4 sm:border-l-2 sm:border-gray-800 sm:py-2 sm:mt-0 mt-4">
                    <a href="https://twitter.com/knyttneve" class="text-gray-500 ml-1" target="_blank"
                        rel="noopener noreferrer"></a>
                </p>
                <span class="inline-flex sm:ml-auto sm:mt-0 mt-4 justify-center sm:justify-start">
                    <a class="text-gray-400" href="https://www.facebook.com/profile.php?id=100089696840410"
                        target="_blank">
                        <svg fill="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                            class="w-5 h-5" viewBox="0 0 24 24">
                            <path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"></path>
                        </svg>
                    </a>
                    <a class="ml-3 text-gray-400" href="https://www.instagram.com/ahmed5800raza/" target="_blank">
                        <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"
                            stroke-width="2" class="w-5 h-5" viewBox="0 0 24 24">
                            <rect width="20" height="20" x="2" y="2" rx="5" ry="5"></rect>
                            <path d="M16 11.37A4 4 0 1112.63 8 4 4 0 0116 11.37zm1.5-4.87h.01"></path>
                        </svg>
                    </a>
                    <a class="ml-3 text-gray-400" href="https://www.linkedin.com/in/ahmed-raza-a9a8372a5/"
                        target="_blank">
                        <svg fill="currentColor" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"
                            stroke-width="0" class="w-5 h-5" viewBox="0 0 24 24">
                            <path stroke="none"
                                d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6zM2 9h4v12H2z">
                            </path>
                            <circle cx="4" cy="4" r="2" stroke="none"></circle>
                        </svg>
                    </a>
                </span>
            </div>
        </footer>






    </body>

    </html>
</body>

</html>